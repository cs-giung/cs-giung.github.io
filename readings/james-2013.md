---
title: /readings/james-2013
layout: page
permalink: /readings/james-2013
---

## A brief history of statistical learning
> from [An Introduction to Statistical Learning (Gareth James et al., 2013)](https://www.statlearning.com/).

---

Though the term _statistical learning_ is fairly new, many of the concepts that underline the field were developed long ago. At the beginning of the nineteenth century, Legendre and Gauss publisehd papers on the _method of least squares_, which implemented the earliest form of what is now known as _linear regression_. The approach was first successfully applied to problems in astronomy. Linear regression is used for predicting quantitative values, such as an individual's salary. In order to predict qualitative values, such as whether a patient survives or dies, or whether the stock market increases or decreases, Fisher proposed _linear discriminant analysis_ in 1936. In the 1940s, various authors put forth an alternative approach, _logistic regression_. In the early 1970s, Nelder and Wedderburn coined the term _generalized linear models_ for an entire class of statistical learning methods that include both linear and logistic regression as special cases.

By the end of the 1970s, many more techniques for learning from data were available. However, they were almost exclusively _linear_ methods, because fitting _non-linear_ relationships was computationally infeasible at the time. By the 1980s, computing technology had finally improved sufficiently that non-linear methods were no longer computationally prohibitive. In mid 1980s Breiman, Friedman, Olshen and Stone introduced _classification and regression trees_, and were among the first to demonstrate the power of a detailed practical implementation of a method, including cross-validation for model selection. Hastie and Tibshirani coined the term _generalized additive models_ in 1986 for a class of non-linear extensions to generalized linear models, and also provided a practical software implementation.

Since that time, inspired by the advent of _machine learning_ and other disciplines, statistical learning has emerged as a new subfield in statistics, focused on supervised and unsupervised modeling and prediction. In recent years, progress in statistical learning has been marked by the increasing availability of powerful and relatively user-friendly software, such as the popular and freely available R system. This has the potential to continue the transformation of the field from a set of techniques used and developed by statisticians and computer scientists to an essential toolkit for a much broader community.
